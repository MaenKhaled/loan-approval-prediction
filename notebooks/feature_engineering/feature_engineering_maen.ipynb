{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442bbd6-52d3-4d07-8dfb-915a326b2ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/souadmouajel/Desktop/Ironhack/lab-sessions/week-7/loan-approval-prediction/data/clean/cleaned_loan_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6728d11-12ff-43a8-909c-629041750fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical columns in order to prepare them for outliers detiction\n",
    "num_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "# Then remove 'loan_id' from that list, if it exists\n",
    "if 'loan_id' in num_cols:\n",
    "    num_cols.remove('loan_id')\n",
    "\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61db33-caa6-4709-98fd-ae7e0d0d31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers detiction \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up boxplots for all numerical columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot((len(num_cols) + 2) // 3, 3, i + 1)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8689749-9378-410a-8b67-26e3f28754e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217c84f-e0d5-451f-b3d6-de217d2bad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "num_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "# Then remove 'loan_id' from that list, if it exists\n",
    "if 'loan_id' in num_cols:\n",
    "    num_cols.remove('loan_id')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot((len(num_cols) + 2) // 3, 3, i + 1)  # arrange plots in rows of 3\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5b156-47df-4df4-bdd5-1a599202173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cbbcc-9bcd-4e36-813d-a0ed58a7b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b4e41-4627-4721-aba3-397e49400531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform the target column\n",
    "# # Step 1.1: Map target labels to binary (1 for Approved, 0 for Rejected)\n",
    "\n",
    "df['loan_status'] = df['loan_status'].map({'approved': 1, 'rejected': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4416a-edb8-489d-bc95-7a6df2bffe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef17b94-7fce-4e82-b218-8487cc3fb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Split features and target, train-test split\n",
    "X = df.drop(columns='loan_status')  # Your full dataset\n",
    "y = df['loan_status']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Drop 'loan_id' if present (don't reset index yet)\n",
    "X_train_raw = X_train_raw.drop(columns=['loan_id'], errors='ignore')\n",
    "X_test_raw = X_test_raw.drop(columns=['loan_id'], errors='ignore')\n",
    "\n",
    "# 3. Define categorical columns\n",
    "categorical_cols = ['education', 'self_employed']\n",
    "\n",
    "# 4. Define numeric columns (all except categorical)\n",
    "numeric_cols = [col for col in X_train_raw.columns if col not in categorical_cols]\n",
    "\n",
    "# 5. Calculate IQR and remove outliers on numeric columns\n",
    "numeric_data = X_train_raw[numeric_cols]  # Don't reset index here\n",
    "\n",
    "Q1 = numeric_data.quantile(0.25)\n",
    "Q3 = numeric_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "filter = ~(\n",
    "    (numeric_data < (Q1 - 1.5 * IQR)) |\n",
    "    (numeric_data > (Q3 + 1.5 * IQR))\n",
    ").any(axis=1)\n",
    "\n",
    "# Now apply the filter (which maintains original indices)\n",
    "X_train_filtered = X_train_raw.loc[filter].reset_index(drop=True)\n",
    "y_train_filtered = y_train.loc[filter].reset_index(drop=True)  # This will now work\n",
    "\n",
    "# 6. Apply OneHotEncoder on filtered training data\n",
    "encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # numeric columns passthrough\n",
    ")\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train_filtered)\n",
    "\n",
    "# 7. Get feature names and rebuild DataFrame\n",
    "cat_encoded_cols = encoder.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "all_columns = list(cat_encoded_cols) + numeric_cols\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_encoded, columns=all_columns)\n",
    "\n",
    "# 8. Convert numeric columns to numeric type explicitly\n",
    "for col in numeric_cols:\n",
    "    X_train_df[col] = pd.to_numeric(X_train_df[col])\n",
    "\n",
    "# 9. Plot boxplot of training features\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.boxplot(data=X_train_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot of Features After Outlier Removal and Encoding')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ebf638-cbfe-4e07-8bd7-1e242776bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Ensure categorical columns exist in data\n",
    "categorical_cols = ['education', 'self_employed']\n",
    "categorical_cols = [col for col in categorical_cols if col in X_train_filtered.columns]\n",
    "\n",
    "# 2. OneHotEncode with error handling\n",
    "try:\n",
    "    encoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        verbose_feature_names_out=False  # Cleaner feature names\n",
    "    )\n",
    "\n",
    "    X_train_encoded = encoder.fit_transform(X_train_filtered)\n",
    "    \n",
    "    # 3. Get feature names\n",
    "    cat_encoded_cols = encoder.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "    numeric_cols = [col for col in X_train_filtered.columns if col not in categorical_cols]\n",
    "    all_columns = list(cat_encoded_cols) + numeric_cols\n",
    "    \n",
    "    # 4. Create DataFrame with proper typing\n",
    "    X_train_df = pd.DataFrame(X_train_encoded, columns=all_columns)\n",
    "    \n",
    "    # Convert numeric columns - more robust handling\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_df.columns:  # Double check column exists\n",
    "            X_train_df[col] = pd.to_numeric(X_train_df[col], errors='coerce')\n",
    "    \n",
    "    # 5. Plotting with improved visuals\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.boxplot(data=X_train_df)\n",
    "    plt.xticks(rotation=45, ha='right')  # Better label alignment\n",
    "    plt.title('Boxplot of Features After Preprocessing')\n",
    "    plt.grid(axis='y', alpha=0.3)  # Add subtle grid\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during encoding: {str(e)}\")\n",
    "    # Fallback to original data if encoding fails\n",
    "    X_train_df = X_train_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204d458-a64d-4a63-ae22-aad6cc306088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove loan_id column if present (more robust check)\n",
    "#X_train_df = X_train_df.drop(columns=['loan_id'], errors='ignore')\n",
    "\n",
    "# 2. Define expected numeric columns with validation\n",
    "expected_numeric_cols = [\n",
    "    'no_of_dependents', 'income_annum', 'loan_amount', 'loan_term',\n",
    "    'cibil_score', 'residential_assets_value', 'commercial_assets_value',\n",
    "    'luxury_assets_value', 'bank_asset_value'\n",
    "]\n",
    "\n",
    "# 3. Find which numeric columns actually exist in our data\n",
    "numeric_cols = [col for col in expected_numeric_cols if col in X_train_df.columns]\n",
    "\n",
    "# 4. Check if we have numeric columns to scale\n",
    "if not numeric_cols:\n",
    "    raise ValueError(\"No valid numeric columns found for scaling. Check your column names.\")\n",
    "\n",
    "# 5. Initialize and apply StandardScaler with proper column validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    # Create a copy of numeric columns to preserve original data\n",
    "    numeric_data = X_train_df[numeric_cols].copy()\n",
    "    \n",
    "    # Initialize and fit scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(numeric_data)\n",
    "    \n",
    "    # Update DataFrame with scaled values\n",
    "    X_train_df[numeric_cols] = scaled_values\n",
    "    \n",
    "    print(f\"Successfully scaled columns: {numeric_cols}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during scaling: {e}\")\n",
    "    # Optionally: preserve original values if scaling fails\n",
    "    # X_train_df[numeric_cols] = numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1bdf7-db94-40a7-8bd1-0dcc81c29474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set style and context for better visuals\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# Create figure with adjusted size\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Create boxplot with enhanced parameters\n",
    "boxplot = sns.boxplot(\n",
    "    data=X_train_df,\n",
    "    palette=\"vlag\",  # Cool blue-red diverging palette\n",
    "    whis=1.5,        # Show outliers beyond 1.5*IQR (standard)\n",
    "    linewidth=1.5,   # Thicker box lines\n",
    "    fliersize=4      # Size of outlier markers\n",
    ")\n",
    "\n",
    "# Improve x-axis labels\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    ha='right',      # Better horizontal alignment\n",
    "    fontsize=12      # Slightly larger font\n",
    ")\n",
    "\n",
    "# Improve y-axis\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel(\"Scaled Values\", fontsize=13, labelpad=10)\n",
    "\n",
    "# Add informative title and subtitle\n",
    "plt.title(\n",
    "    \"Distribution of Features After Standard Scaling\",\n",
    "    fontsize=16,\n",
    "    pad=20\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"Showing median, quartiles, and outliers for all processed features\",\n",
    "    y=0.95,\n",
    "    fontsize=12,\n",
    "    color='gray'\n",
    ")\n",
    "\n",
    "# Add horizontal grid lines for better readability\n",
    "plt.grid(axis='y', alpha=0.4, linestyle='--')\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add annotation for scaled features\n",
    "if len(numeric_cols) > 0:\n",
    "    plt.annotate(\n",
    "        f\"Note: {len(numeric_cols)} numeric features were standardized\",\n",
    "        xy=(0.5, -0.15),\n",
    "        xycoords='axes fraction',\n",
    "        ha='center',\n",
    "        fontsize=11,\n",
    "        color='dimgray'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee145e-ced0-4161-9fc9-bfb66547c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Add target for correlation check\n",
    "df_corr = X_train_df.copy()\n",
    "df_corr['loan_status'] = y_train_filtered\n",
    "\n",
    "# 10. Compute correlation matrix and plot heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = df_corr.corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title('Correlation matrix including Target (loan_status)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01906879-7c09-4e09-9c9e-298b84bc017c",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceff779-18ba-4e0a-bb64-150449ca56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove 'loan_id' if present (same as training)\n",
    "X_test_raw = X_test_raw.drop(columns=['loan_id'], errors='ignore')\n",
    "\n",
    "# 2. Apply the same outlier filter (using training's IQR thresholds)\n",
    "# Use the IQR values calculated from training data\n",
    "test_numeric_data = X_test_raw[numeric_cols]  # Use same numeric_cols from training\n",
    "\n",
    "test_filter = ~(\n",
    "    (test_numeric_data < (Q1 - 1.5 * IQR)) | \n",
    "    (test_numeric_data > (Q3 + 1.5 * IQR))\n",
    ").any(axis=1)\n",
    "\n",
    "X_test_filtered = X_test_raw.loc[test_filter].reset_index(drop=True)\n",
    "y_test_filtered = y_test.loc[test_filter].reset_index(drop=True)\n",
    "\n",
    "# 3. Apply the trained encoder to test data (no fit!)\n",
    "X_test_encoded = encoder.transform(X_test_filtered)  # Use the same encoder from training\n",
    "\n",
    "# 4. Create DataFrame with same columns as training\n",
    "X_test_df = pd.DataFrame(X_test_encoded, columns=all_columns)  # Use same all_columns\n",
    "\n",
    "# 5. Convert numeric columns (same as training)\n",
    "for col in numeric_cols:\n",
    "    X_test_df[col] = pd.to_numeric(X_test_df[col], errors='coerce')\n",
    "\n",
    "# 6. Apply the trained scaler to test data (no fit!)\n",
    "X_test_df[numeric_cols] = scaler.transform(X_test_df[numeric_cols])  # Use same scaler\n",
    "\n",
    "# 7. (Optional) Visualize test data distributions\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.boxplot(data=X_test_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot of Test Data After Preprocessing')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f9fc-8711-4d47-aa17-fa6e454c7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create correlation dataframe (with proper target alignment)\n",
    "df_corr = X_test_df.copy()\n",
    "df_corr['loan_status'] = y_test_filtered.values  # Ensure alignment\n",
    "\n",
    "# 2. Compute correlation matrix with error handling\n",
    "try:\n",
    "    corr_matrix = df_corr.corr(numeric_only=True)  # Only numeric columns\n",
    "except Exception as e:\n",
    "    print(f\"Correlation calculation error: {e}\")\n",
    "    # Fallback to only numeric columns if mixed data types\n",
    "    numeric_cols = df_corr.select_dtypes(include=['number']).columns\n",
    "    corr_matrix = df_corr[numeric_cols].corr()\n",
    "\n",
    "# 3. Enhanced heatmap visualization\n",
    "plt.figure(figsize=(14, 12))\n",
    "heatmap = sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    linewidths=0.5,\n",
    "    linecolor='lightgray',\n",
    "    cbar_kws={'shrink': 0.8, 'label': 'Correlation Coefficient'}\n",
    ")\n",
    "\n",
    "# 4. Improve title and labels\n",
    "plt.title(\n",
    "    'Test Set Feature Correlations with Target (loan_status)\\n',\n",
    "    fontsize=16,\n",
    "    pad=20\n",
    ")\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    ha='right',\n",
    "    fontsize=10\n",
    ")\n",
    "plt.yticks(\n",
    "    rotation=0,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# 5. Highlight target correlations\n",
    "if 'loan_status' in corr_matrix.columns:\n",
    "    target_corrs = corr_matrix['loan_status'].drop('loan_status')\n",
    "    top_features = target_corrs.abs().sort_values(ascending=False).head(3).index\n",
    "    \n",
    "    # Annotate top features\n",
    "    for feature in top_features:\n",
    "        idx = corr_matrix.index.get_loc(feature)\n",
    "        heatmap.add_patch(plt.Rectangle(\n",
    "            (corr_matrix.columns.get_loc('loan_status'), idx),\n",
    "            1, 1, fill=False, edgecolor='gold', lw=2\n",
    "        ))\n",
    "\n",
    "# 6. Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print top correlations with target\n",
    "if 'loan_status' in corr_matrix.columns:\n",
    "    print(\"\\nTop correlations with loan_status:\")\n",
    "    print(target_corrs.abs().sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d15760-6982-49b9-8d72-92aef1ba06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation values explicitly\n",
    "print(df_corr.corr(numeric_only=True)['loan_status'].sort_values(ascending=False))\n",
    "\n",
    "# Plot the relationship\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df_corr, x='loan_status', y='cibil_score')\n",
    "plt.title('Loan Status vs. CIBIL Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ceaf2-b739-436d-874f-4fbff057d454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
