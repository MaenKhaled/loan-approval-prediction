{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199ebb8-bee9-439a-9c9e-9aaad6e517b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            classification_report, roc_curve, precision_recall_curve)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f43a4-7756-4f6f-85e0-ac85c75a815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, X, y, model_name=\"\"):\n",
    "    \"\"\"Generate all evaluation metrics and plots\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else [0]*len(y)\n",
    "    \n",
    "    # Metrics\n",
    "    print(f\"\\n{'='*50}\\nEvaluation for {model_name}\\n{'='*50}\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y, y_proba):.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y, y_proba):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(recall, precision, label=model_name)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare feature sets\n",
    "X_train_all = X_train_df\n",
    "X_test_all = X_test_df\n",
    "X_train_cibil = X_train_df[['cibil_score']]\n",
    "X_test_cibil = X_test_df[['cibil_score']]\n",
    "\n",
    "# Model 1: Logistic Regression (All Features)\n",
    "lr_all = LogisticRegression(max_iter=1000)\n",
    "lr_all.fit(X_train_all, y_train_filtered)\n",
    "evaluate_model(lr_all, X_test_all, y_test_filtered, \"LogReg (All Features)\")\n",
    "\n",
    "# Model 2: Logistic Regression (Only CIBIL)\n",
    "lr_cibil = LogisticRegression(max_iter=1000)\n",
    "lr_cibil.fit(X_train_cibil, y_train_filtered)\n",
    "evaluate_model(lr_cibil, X_test_cibil, y_test_filtered, \"LogReg (CIBIL Only)\")\n",
    "\n",
    "# Model 3: Random Forest (All Features)\n",
    "rf_all = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_all.fit(X_train_all, y_train_filtered)\n",
    "evaluate_model(rf_all, X_test_all, y_test_filtered, \"Random Forest (All Features)\")\n",
    "\n",
    "# Model 4: Random Forest (Only CIBIL)\n",
    "rf_cibil = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cibil.fit(X_train_cibil, y_train_filtered)\n",
    "evaluate_model(rf_cibil, X_test_cibil, y_test_filtered, \"Random Forest (CIBIL Only)\")\n",
    "\n",
    "# Feature Importance Plot (for RF with all features)\n",
    "plt.figure(figsize=(10,6))\n",
    "pd.Series(rf_all.feature_importances_, index=X_train_all.columns\n",
    "         ).sort_values().plot.barh(title='Random Forest Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b474e0a-32cd-41e4-b98b-caa9a82a772f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
